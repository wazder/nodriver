"""
Sahibinden.com Safe Scraper
============================
- 403 engelini aÅŸmak iÃ§in SADECE nodriver (browser) kullanÄ±r
- curl_cffi yok - tÃ¼m istekler browser Ã¼zerinden
- Random delay ile insan gibi davranÄ±ÅŸ
- Cookie persistence
- Otomatik login + Gmail'den 2FA kodu okuma
"""
import asyncio
import json
import random
import os
import re
import imaplib
import email
from email.header import decode_header
from datetime import datetime, timedelta
from pathlib import Path
import time

import nodriver as uc

# Login bilgileri
CREDENTIALS = {
    "email": "wwazder@gmail.com",
    "password": "BombaYagiyo31"
}

# Gmail IMAP - 2FA kodunu otomatik almak iÃ§in
GMAIL_IMAP = {
    "email": "wwazder@gmail.com",
    "app_password": "rxlkdfxwbhlanqhy"  # boÅŸluksuz
}

# Dosya yollarÄ±
COOKIE_FILE = Path(__file__).parent / "sahibinden_cookies.json"
DATA_DIR = Path(__file__).parent / "kellerwilliams_data"
DATA_DIR.mkdir(exist_ok=True)


class SafeScraper:
    """403'Ã¼ aÅŸmak iÃ§in gÃ¼venli scraper - sadece browser kullanÄ±r"""
    
    def __init__(self):
        self.browser = None
        self.page = None
        self.cookies = {}
    
    def get_2fa_code_from_gmail(self, max_wait=60) -> str:
        """Gmail'den Sahibinden 2FA kodunu oku"""
        print("ğŸ“§ Gmail'den 2FA kodu bekleniyor...")
        
        start_time = time.time()
        seen_codes = set()  # Daha Ã¶nce gÃ¶rÃ¼len kodlarÄ± takip et
        
        while time.time() - start_time < max_wait:
            try:
                # Gmail IMAP'a baÄŸlan
                mail = imaplib.IMAP4_SSL("imap.gmail.com")
                mail.login(GMAIL_IMAP["email"], GMAIL_IMAP["app_password"])
                mail.select("INBOX")
                
                # Son 1 dakikadaki UNREAD Sahibinden maillerini ara
                # NOT: "sahibinden" kelimesini FROM veya SUBJECT'te ara
                _, messages = mail.search(None, '(UNSEEN FROM "sahibinden")')
                
                if not messages[0]:
                    # UNSEEN bulamazsan son 2 dakikadaki tÃ¼m Sahibinden maillerine bak
                    date_since = (datetime.now() - timedelta(minutes=2)).strftime("%d-%b-%Y")
                    _, messages = mail.search(None, f'(FROM "sahibinden" SINCE "{date_since}")')
                
                if messages[0]:
                    # En son maili al
                    latest_id = messages[0].split()[-1]
                    _, msg_data = mail.fetch(latest_id, "(RFC822)")
                    
                    for response_part in msg_data:
                        if isinstance(response_part, tuple):
                            msg = email.message_from_bytes(response_part[1])
                            
                            # Mail tarihini kontrol et
                            date_str = msg.get('Date', '')
                            
                            # Mail iÃ§eriÄŸini al
                            body = ""
                            if msg.is_multipart():
                                for part in msg.walk():
                                    if part.get_content_type() == "text/plain":
                                        body = part.get_payload(decode=True).decode('utf-8', errors='ignore')
                                        break
                                    elif part.get_content_type() == "text/html":
                                        body = part.get_payload(decode=True).decode('utf-8', errors='ignore')
                            else:
                                body = msg.get_payload(decode=True).decode('utf-8', errors='ignore')
                            
                            # 6 haneli kodu bul (4-6 haneli olabilir)
                            codes = re.findall(r'\b(\d{4,6})\b', body)
                            for code in codes:
                                # Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ kodu dÃ¶ndÃ¼r
                                if code not in seen_codes and len(code) >= 4:
                                    print(f"   âœ… Yeni kod bulundu: {code}")
                                    mail.logout()
                                    return code
                                else:
                                    seen_codes.add(code)
                
                mail.logout()
                
            except Exception as e:
                print(f"   âš ï¸ Gmail hatasÄ±: {e}")
            
            print(f"   â³ Yeni mail bekleniyor... ({int(time.time() - start_time)}s)")
            time.sleep(3)
        
        print("   âŒ Kod bulunamadÄ±, manuel giriÅŸ gerekiyor")
        return None
        
    async def type_like_human(self, text: str, delay_min=0.05, delay_max=0.15):
        """Ä°nsan gibi tek tek karakter yaz - CDP ile gerÃ§ek klavye eventi"""
        for char in text:
            # insertText kullan - Ã¶zel karakterler iÃ§in daha gÃ¼venilir
            await self.page.send(uc.cdp.input_.insert_text(text=char))
            # Ä°nsan gibi rastgele gecikme
            await asyncio.sleep(random.uniform(delay_min, delay_max))
    
    async def random_delay(self, min_sec=2, max_sec=5):
        """Ä°nsan gibi rastgele bekleme"""
        delay = random.uniform(min_sec, max_sec)
        await asyncio.sleep(delay)
        
    async def start(self):
        """Browser baÅŸlat"""
        print("=" * 60)
        print("ğŸ  SAHÄ°BÄ°NDEN SAFE SCRAPER (Browser Only)")
        print("   403 korumasÄ± iÃ§in sadece browser kullanÄ±lÄ±yor")
        print("=" * 60)
        
        # Browser'Ä± daha gerÃ§ekÃ§i ayarlarla baÅŸlat
        self.browser = await uc.start(
            headless=False,
            browser_args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--no-first-run',
                '--no-default-browser-check',
            ]
        )
        
        print("\nğŸŒ Sahibinden.com'a baÄŸlanÄ±lÄ±yor...")
        self.page = await self.browser.get("https://www.sahibinden.com")
        await asyncio.sleep(3)
        
        # Press & Hold CAPTCHA kontrolÃ¼
        await self._handle_press_hold_captcha()
        
        # Ã‡erez popup'Ä±nÄ± kapat
        await self._close_cookie_popup()
        
        # Cookie'leri yÃ¼kle veya login yap
        if await self._load_and_verify_cookies():
            print("âœ… KaydedilmiÅŸ session aktif!")
        else:
            await self._manual_login()
        
        return True
    
    async def _handle_press_hold_captcha(self):
        """Press and Hold CAPTCHA'yÄ± geÃ§ - kullanÄ±cÄ±dan manuel mÃ¼dahale ister"""
        for attempt in range(3):
            try:
                current_url = await self.page.evaluate("window.location.href")
                page_text = await self.page.evaluate("document.body.innerText.substring(0, 1000)")
                
                # CAPTCHA sayfasÄ± mÄ± kontrol et
                is_captcha = 'hloading' in str(current_url) or \
                             'basÄ±lÄ±' in str(page_text).lower() or \
                             'tutunuz' in str(page_text).lower() or \
                             'hold' in str(page_text).lower() or \
                             'tarayÄ±cÄ±nÄ±zÄ± kontrol' in str(page_text).lower()
                
                if not is_captcha:
                    return True  # CAPTCHA yok, devam et
                
                print(f"\n   ğŸ¤– CAPTCHA tespit edildi!")
                print("   ğŸ‘† LÃ¼tfen tarayÄ±cÄ±da 'BasÄ±lÄ± Tutunuz' butonuna basÄ±lÄ± tut!")
                print("   â³ CAPTCHA geÃ§ene kadar bekliyorum...")
                
                # KullanÄ±cÄ±nÄ±n CAPTCHA'yÄ± manuel geÃ§mesini bekle
                for wait in range(60):  # Max 120 saniye bekle
                    await asyncio.sleep(2)
                    
                    new_url = await self.page.evaluate("window.location.href")
                    
                    # CAPTCHA geÃ§ildi mi?
                    if 'hloading' not in str(new_url):
                        print("   âœ… CAPTCHA geÃ§ildi!")
                        await asyncio.sleep(2)
                        return True
                    
                    if wait % 10 == 0 and wait > 0:
                        print(f"   â³ Hala bekliyorum... ({wait * 2}s)")
                
            except Exception as e:
                print(f"   âš ï¸ CAPTCHA kontrol hatasÄ±: {e}")
        
        return False
    
    async def _close_cookie_popup(self):
        """Ã‡erez popup'Ä±nÄ± kapat"""
        try:
            accept_btn = await self.page.find("Kabul Et", timeout=3)
            if accept_btn:
                await accept_btn.click()
                await asyncio.sleep(1)
                print("ğŸª Ã‡erez popup'Ä± kapatÄ±ldÄ±")
        except:
            pass
    
    async def _load_and_verify_cookies(self) -> bool:
        """Cookie yÃ¼kle ve doÄŸrula"""
        if not COOKIE_FILE.exists():
            print("ğŸ“ KayÄ±tlÄ± cookie bulunamadÄ±")
            return False
        
        try:
            with open(COOKIE_FILE, 'r') as f:
                data = json.load(f)
            
            cookies = data.get('cookies', [])
            print(f"ğŸ“ {len(cookies)} cookie yÃ¼kleniyor...")
            
            # Cookie'leri browser'a ekle
            for c in cookies:
                try:
                    await self.page.send(uc.cdp.network.set_cookie(
                        name=c['name'],
                        value=c['value'],
                        domain=c.get('domain', '.sahibinden.com'),
                        path=c.get('path', '/')
                    ))
                except:
                    pass
            
            # SayfayÄ± yenile
            await self.page.reload()
            await asyncio.sleep(3)
            
            # Session kontrolÃ¼
            return await self._is_logged_in()
            
        except Exception as e:
            print(f"âŒ Cookie yÃ¼kleme hatasÄ±: {e}")
            return False
    
    async def _is_logged_in(self) -> bool:
        """GiriÅŸ yapÄ±lmÄ±ÅŸ mÄ± kontrol et"""
        try:
            check_js = """
            (() => {
                // "GiriÅŸ Yap" butonu varsa giriÅŸ yapÄ±lmamÄ±ÅŸ
                const loginText = document.body.innerText;
                if (loginText.includes('GiriÅŸ Yap') && loginText.includes('Ãœye Ol')) {
                    return 'not_logged_in';
                }
                // "Ã‡Ä±kÄ±ÅŸ" veya "HesabÄ±m" varsa giriÅŸ yapÄ±lmÄ±ÅŸ
                if (loginText.includes('Ã‡Ä±kÄ±ÅŸ') || loginText.includes('HesabÄ±m')) {
                    return 'logged_in';
                }
                return 'unknown';
            })()
            """
            result = await self.page.evaluate(check_js)
            result_str = str(result)
            
            if 'logged_in' in result_str and 'not_' not in result_str:
                print("   âœ… GiriÅŸ yapÄ±lmÄ±ÅŸ")
                return True
            elif 'not_logged_in' in result_str:
                print("   âŒ GiriÅŸ yapÄ±lmamÄ±ÅŸ")
                return False
            else:
                print(f"   âš ï¸ Belirsiz durum: {result_str[:50]}")
                return False
        except Exception as e:
            print(f"   Login kontrol hatasÄ±: {e}")
            return False
    
    async def _manual_login(self):
        """Otomatik login - her adÄ±mda validation ile"""
        print("\n" + "=" * 60)
        print("ğŸ” OTOMATÄ°K LOGIN (Validation Enabled)")
        print("=" * 60)
        
        # ========== ADIM 0: Login sayfasÄ±na git ==========
        print("\n[ADIM 0] Login sayfasÄ±na gidiliyor...")
        await self.page.get("https://www.sahibinden.com/giris")
        await asyncio.sleep(4)
        
        # Validation 0: Login sayfasÄ±nda mÄ±yÄ±z?
        current_url = await self.page.evaluate("window.location.href")
        if 'giris' not in str(current_url).lower() and 'login' not in str(current_url).lower():
            print(f"   âŒ VALIDATION FAILED: Login sayfasÄ±na ulaÅŸÄ±lamadÄ±!")
            print(f"   ğŸ“ Mevcut URL: {current_url}")
            # CAPTCHA olabilir
            await self._handle_press_hold_captcha()
            # Tekrar dene
            await self.page.get("https://www.sahibinden.com/giris")
            await asyncio.sleep(3)
        
        current_url = await self.page.evaluate("window.location.href")
        print(f"   âœ… VALIDATION OK: Login sayfasÄ±ndayÄ±z")
        print(f"   ğŸ“ URL: {current_url}")
        
        try:
            # ========== ADIM 1: Email alanÄ±nÄ± bul ==========
            print("\n[ADIM 1] Email alanÄ± aranÄ±yor...")
            
            email_input = await self.page.select('input[name="username"], input[type="email"], input[placeholder*="posta"], input[placeholder*="mail"]')
            
            # Validation 1a: Email alanÄ± bulundu mu?
            if not email_input:
                print("   âŒ VALIDATION FAILED: Email alanÄ± bulunamadÄ±!")
                # Debug: Sayfadaki input'larÄ± listele
                inputs = await self.page.evaluate("""
                    [...document.querySelectorAll('input')].map(i => ({
                        name: i.name, type: i.type, placeholder: i.placeholder, id: i.id
                    }))
                """)
                print(f"   ğŸ“Š Sayfadaki input'lar: {inputs}")
                return False
            
            print("   âœ… VALIDATION OK: Email alanÄ± bulundu")
            
            # ========== ADIM 2: Email gir ==========
            print("\n[ADIM 2] Email giriliyor...")
            await email_input.click()
            await asyncio.sleep(0.3)
            
            # AlanÄ± temizle
            await self.page.send(uc.cdp.input_.dispatch_key_event(type_="keyDown", key="a", code="KeyA", modifiers=2))
            await self.page.send(uc.cdp.input_.dispatch_key_event(type_="keyUp", key="a", code="KeyA"))
            await asyncio.sleep(0.1)
            await self.page.send(uc.cdp.input_.dispatch_key_event(type_="keyDown", key="Backspace", code="Backspace"))
            await self.page.send(uc.cdp.input_.dispatch_key_event(type_="keyUp", key="Backspace", code="Backspace"))
            await asyncio.sleep(0.3)
            
            # Email yaz
            await self.type_like_human(CREDENTIALS["email"])
            await asyncio.sleep(0.5)
            
            # Validation 2: Email doÄŸru girildi mi?
            email_value = await self.page.evaluate("""
                document.querySelector('input[name="username"], input[type="email"]')?.value || ''
            """)
            email_value = str(email_value).replace("{'type': 'string', 'value': '", "").replace("'}", "")
            
            if CREDENTIALS["email"] not in email_value:
                print(f"   âŒ VALIDATION FAILED: Email doÄŸru girilmedi!")
                print(f"   ğŸ“Š Beklenen: {CREDENTIALS['email']}")
                print(f"   ğŸ“Š Girilen: {email_value}")
                return False
            
            print(f"   âœ… VALIDATION OK: Email doÄŸru girildi: {email_value}")
            
            # ========== ADIM 3: Åifre alanÄ±na geÃ§ ==========
            print("\n[ADIM 3] Åifre alanÄ±na geÃ§iliyor (Tab)...")
            await self.page.send(uc.cdp.input_.dispatch_key_event(type_="keyDown", key="Tab", code="Tab"))
            await self.page.send(uc.cdp.input_.dispatch_key_event(type_="keyUp", key="Tab", code="Tab"))
            await asyncio.sleep(0.5)
            
            # Validation 3: Åifre alanÄ±na focus geldi mi?
            focused_type = await self.page.evaluate("""
                document.activeElement?.type || document.activeElement?.tagName || 'unknown'
            """)
            focused_type = str(focused_type)
            
            if 'password' not in focused_type.lower():
                print(f"   âš ï¸ VALIDATION WARNING: Focus password alanÄ±nda olmayabilir")
                print(f"   ğŸ“Š Focus: {focused_type}")
                # Manuel olarak ÅŸifre alanÄ±na tÄ±kla
                password_input = await self.page.select('input[type="password"]')
                if password_input:
                    await password_input.click()
                    await asyncio.sleep(0.3)
                    print("   ğŸ”„ Åifre alanÄ±na manuel tÄ±klandÄ±")
            else:
                print(f"   âœ… VALIDATION OK: Åifre alanÄ±nda focus var")
            
            # ========== ADIM 4: Åifre gir ==========
            print("\n[ADIM 4] Åifre giriliyor...")
            await self.type_like_human(CREDENTIALS["password"])
            await asyncio.sleep(0.5)
            
            # Validation 4: Åifre girildi mi?
            password_value = await self.page.evaluate("""
                document.querySelector('input[type="password"]')?.value?.length || 0
            """)
            password_len = int(str(password_value).replace("{'type': 'number', 'value': ", "").replace("}", ""))
            
            if password_len < 3:
                print(f"   âŒ VALIDATION FAILED: Åifre girilmedi veya Ã§ok kÄ±sa!")
                print(f"   ğŸ“Š Åifre uzunluÄŸu: {password_len}")
                return False
            
            print(f"   âœ… VALIDATION OK: Åifre girildi ({password_len} karakter)")
            
            # ========== ADIM 5: GiriÅŸ butonuna bas ==========
            print("\n[ADIM 5] GiriÅŸ butonuna basÄ±lÄ±yor...")
            
            # URL'yi kaydet (karÅŸÄ±laÅŸtÄ±rma iÃ§in)
            url_before = await self.page.evaluate("window.location.href")
            
            # Enter tuÅŸuna bas
            await self.page.send(uc.cdp.input_.dispatch_key_event(
                type_="keyDown", key="Enter", code="Enter",
                windows_virtual_key_code=13, native_virtual_key_code=13
            ))
            await self.page.send(uc.cdp.input_.dispatch_key_event(
                type_="keyUp", key="Enter", code="Enter"
            ))
            print("   â³ Enter tuÅŸuna basÄ±ldÄ±, sayfa yÃ¼kleniyor...")
            
            await asyncio.sleep(6)
            
            # Validation 5: URL deÄŸiÅŸti mi?
            url_after = await self.page.evaluate("window.location.href")
            
            if str(url_before) == str(url_after):
                print(f"   âš ï¸ VALIDATION WARNING: URL deÄŸiÅŸmedi!")
                print(f"   ğŸ“ URL: {url_after}")
                
                # Hata mesajÄ± var mÄ± kontrol et
                error_msg = await self.page.evaluate("""
                    document.querySelector('.error, .alert, [class*="error"], [class*="alert"]')?.innerText || ''
                """)
                if error_msg:
                    print(f"   âŒ Hata mesajÄ±: {error_msg}")
                
                # Belki giriÅŸ butonu var hala - tÄ±klamayÄ± dene
                print("   ğŸ”„ GiriÅŸ butonuna tÄ±klamayÄ± deniyorum...")
                login_btn = await self.page.find("E-posta ile giriÅŸ yap", timeout=3)
                if login_btn:
                    await login_btn.click()
                    await asyncio.sleep(5)
                    url_after = await self.page.evaluate("window.location.href")
            
            print(f"   ğŸ“ Yeni URL: {url_after}")
            
            # CAPTCHA kontrolÃ¼
            if 'hloading' in str(url_after):
                print("   âš ï¸ CAPTCHA tespit edildi!")
                await self._handle_press_hold_captcha()
                url_after = await self.page.evaluate("window.location.href")
            
            # ========== ADIM 6: 2FA kontrolÃ¼ ==========
            print("\n[ADIM 6] 2FA kontrolÃ¼ yapÄ±lÄ±yor...")
            page_text = await self.page.evaluate("document.body.innerText")
            
            is_2fa = 'dogrulama' in str(url_after).lower() or \
                     'verification' in str(url_after).lower() or \
                     'onay kodu' in str(page_text).lower() or \
                     'doÄŸrulama kodu' in str(page_text).lower()
            
            is_still_login = 'giris' in str(url_after).lower() or 'login' in str(url_after).lower()
            
            if is_still_login and not is_2fa:
                print("   âŒ VALIDATION FAILED: Hala login sayfasÄ±ndayÄ±z!")
                print("   ğŸ“Š GiriÅŸ baÅŸarÄ±sÄ±z olmuÅŸ olabilir")
                
                # Manuel mÃ¼dahale iste
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(None, lambda: input(">>> Manuel giriÅŸ yapÄ±p ENTER'a basÄ±n: "))
                url_after = await self.page.evaluate("window.location.href")
            
            if is_2fa:
                
                print("\n" + "=" * 50)
                print("ğŸ“§ EMAIL 2FA - OTOMATÄ°K KOD OKUMA")
                print("=" * 50)
                
                # Gmail'den kodu al
                code = self.get_2fa_code_from_gmail(max_wait=90)
                
                if code:
                    # Kodu otomatik gir
                    print(f"ğŸ”¢ Kod giriliyor: {code}")
                    code_input = await self.page.select('input[name="code"], input[type="text"], input[type="tel"], input[type="number"]')
                    if code_input:
                        await code_input.click()
                        await asyncio.sleep(0.5)
                        await code_input.send_keys(code)
                        await asyncio.sleep(1)
                        
                        # DoÄŸrula butonuna tÄ±kla
                        verify_btn = await self.page.select('button[type="submit"], input[type="submit"]')
                        if verify_btn:
                            await verify_btn.click()
                        else:
                            verify_btn = await self.page.find("DoÄŸrula", timeout=3)
                            if verify_btn:
                                await verify_btn.click()
                        
                        await asyncio.sleep(3)
                        print("âœ… 2FA kodu girildi!")
                        
                        # 2FA sonrasÄ± CAPTCHA kontrolÃ¼
                        await self._handle_press_hold_captcha()
                else:
                    # Manuel giriÅŸ
                    print("""
   âŒ Otomatik kod alÄ±namadÄ±!
   
   LÃ¼tfen:
   1. Email'ini kontrol et
   2. Kodu tarayÄ±cÄ±ya gir
   3. ENTER'a bas
""")
                    loop = asyncio.get_event_loop()
                    await loop.run_in_executor(None, lambda: input(">>> ENTER: "))
                    
                    # Manuel 2FA sonrasÄ± da CAPTCHA kontrolÃ¼
                    await self._handle_press_hold_captcha()
            
            # Login sonrasÄ± CAPTCHA kontrolÃ¼
            await self._handle_press_hold_captcha()
            
            # Ana sayfaya git
            current_url = await self.page.evaluate("window.location.href")
            if 'sahibinden.com' in str(current_url) and 'giris' not in str(current_url).lower():
                print("âœ… Login baÅŸarÄ±lÄ±, ana sayfaya geÃ§iliyor...")
            
            await self.page.get("https://www.sahibinden.com")
            await asyncio.sleep(3)
            
            # Ana sayfa sonrasÄ± da CAPTCHA kontrolÃ¼
            await self._handle_press_hold_captcha()
            
        except Exception as e:
            print(f"âŒ Login hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, lambda: input(">>> Manuel login yapÄ±p ENTER'a basÄ±n: "))
        
        await self._save_cookies()
        print("âœ… Session kaydedildi!")
    
    async def _save_cookies(self):
        """Cookie kaydet"""
        try:
            cookie_str = await self.page.evaluate("document.cookie")
            cookies = []
            for item in str(cookie_str).split(';'):
                if '=' in item:
                    name, value = item.strip().split('=', 1)
                    cookies.append({
                        'name': name.strip(),
                        'value': value.strip(),
                        'domain': '.sahibinden.com',
                        'path': '/'
                    })
            
            with open(COOKIE_FILE, 'w') as f:
                json.dump({
                    'cookies': cookies,
                    'saved_at': datetime.now().isoformat()
                }, f, indent=2)
            
            print(f"ğŸ’¾ {len(cookies)} cookie kaydedildi")
        except Exception as e:
            print(f"âŒ Cookie kaydetme hatasÄ±: {e}")
    
    async def get_page_safe(self, url: str, retry=3) -> bool:
        """GÃ¼venli sayfa yÃ¼kleme - 403 ve CAPTCHA kontrolÃ¼ ile"""
        for attempt in range(retry):
            try:
                await self.page.get(url)
                await self.random_delay(2, 4)
                
                # Press & Hold CAPTCHA kontrolÃ¼
                current_url = await self.page.evaluate("window.location.href")
                if 'hloading' in str(current_url):
                    await self._handle_press_hold_captcha()
                
                # 403 kontrolÃ¼
                page_text = await self.page.evaluate("document.body.innerText.substring(0, 500)")
                page_text = str(page_text).lower()
                
                if '403' in page_text or 'forbidden' in page_text or 'eriÅŸim engellendi' in page_text:
                    print(f"   âš ï¸ 403 tespit edildi, {10 + attempt*5} saniye bekleniyor...")
                    await asyncio.sleep(10 + attempt * 5)
                    continue
                
                # BasÄ±lÄ± tutunuz kontrolÃ¼
                if 'basÄ±lÄ± tutunuz' in page_text or 'basili tutunuz' in page_text:
                    await self._handle_press_hold_captcha()
                
                # Normal Captcha kontrolÃ¼
                if 'robot' in page_text or 'captcha' in page_text:
                    print("   âš ï¸ Captcha tespit edildi!")
                    print("   LÃ¼tfen tarayÄ±cÄ±da captcha'yÄ± Ã§Ã¶zÃ¼n ve ENTER'a basÄ±n")
                    loop = asyncio.get_event_loop()
                    await loop.run_in_executor(None, lambda: input(">>> ENTER: "))
                    continue
                
                return True
                
            except Exception as e:
                print(f"   Hata: {e}, tekrar deneniyor...")
                await asyncio.sleep(5)
        
        return False
    
    async def scrape_store(self, store_url: str = "https://kellerwillamskarma.sahibinden.com"):
        """MaÄŸazayÄ± scrape et"""
        print(f"\nğŸª MaÄŸaza: {store_url}")
        
        # 1. Ä°lan URL'lerini topla
        print("\n" + "â”€" * 50)
        print("ğŸ“‹ ADIM 1: Ä°lan URL'leri toplanÄ±yor...")
        print("â”€" * 50)
        
        all_urls = []
        page_num = 0
        max_pages = 10
        
        while page_num < max_pages:
            offset = page_num * 50
            url = f"{store_url}?pagingOffset={offset}" if page_num > 0 else store_url
            
            print(f"\nğŸ“„ Sayfa {page_num + 1}...")
            
            if not await self.get_page_safe(url):
                print("   âŒ Sayfa yÃ¼klenemedi")
                break
            
            # Debug: Mevcut URL'yi kontrol et
            current_url = await self.page.evaluate("window.location.href")
            print(f"   ğŸ“ Mevcut URL: {current_url}")
            
            # Debug: Sayfa iÃ§eriÄŸi
            debug_info = await self.page.evaluate("""
                (() => {
                    return {
                        url: window.location.href,
                        title: document.title,
                        linkCount: document.querySelectorAll('a').length,
                        ilanLinks: document.querySelectorAll('a[href*="/ilan/"]').length,
                        detayLinks: [...document.querySelectorAll('a[href*="/ilan/"]')].filter(a => a.href.includes('/detay')).length,
                        bodyPreview: document.body.innerText.substring(0, 200)
                    };
                })()
            """)
            print(f"   ğŸ“Š Debug: {debug_info}")
            
            # CAPTCHA kontrolÃ¼
            if 'hloading' in str(current_url) or 'basÄ±lÄ±' in str(debug_info).lower():
                print("   âš ï¸ CAPTCHA tespit edildi!")
                await self._handle_press_hold_captcha()
                continue
            
            # Ä°lan linklerini Ã§ek
            links = await self.page.evaluate("""
                [...document.querySelectorAll('a[href*="/ilan/"]')]
                    .map(a => a.href)
                    .filter(h => h.includes('/detay'))
            """)
            
            # Nodriver value extraction
            if isinstance(links, list):
                for item in links:
                    if isinstance(item, dict) and 'value' in item:
                        all_urls.append(item['value'])
                    elif isinstance(item, str):
                        all_urls.append(item)
            
            unique_count = len(set(all_urls))
            print(f"   âœ“ Toplam {unique_count} benzersiz URL")
            
            # Son sayfaya ulaÅŸtÄ±ysak dur
            current_page_links = await self.page.evaluate("""
                document.querySelectorAll('a[href*="/ilan/"]').length
            """)
            if isinstance(current_page_links, dict):
                current_page_links = current_page_links.get('value', 0)
            
            if int(current_page_links) < 5:
                print("   Son sayfaya ulaÅŸÄ±ldÄ±")
                break
            
            page_num += 1
            await self.random_delay(3, 6)  # Sayfalar arasÄ± bekleme
        
        all_urls = list(set(all_urls))
        print(f"\nğŸ“‹ Toplam {len(all_urls)} ilan bulundu")
        
        # URL'leri kaydet
        with open(DATA_DIR / "listing_urls.json", 'w') as f:
            json.dump(all_urls, f, indent=2)
        
        # 2. Her ilanÄ±n detayÄ±nÄ± Ã§ek
        print("\n" + "â”€" * 50)
        print("ğŸ“„ ADIM 2: Ä°lan detaylarÄ± Ã§ekiliyor...")
        print("â”€" * 50)
        
        all_listings = []
        
        for i, url in enumerate(all_urls):
            print(f"\n[{i+1}/{len(all_urls)}] {url[:60]}...")
            
            listing = await self.scrape_listing(url)
            if listing:
                all_listings.append(listing)
                print(f"   âœ“ {listing.get('title', 'N/A')[:40]}")
                print(f"   ğŸ’° {listing.get('price', 'N/A')} | ğŸ“· {len(listing.get('images', []))} foto")
            else:
                print("   âŒ Ã‡ekilemedi")
            
            # Her 10 ilanda kaydet
            if (i + 1) % 10 == 0:
                self._save_listings(all_listings)
                print(f"\nğŸ’¾ {len(all_listings)} ilan kaydedildi")
            
            # Random bekleme
            await self.random_delay(3, 7)
        
        # Final kaydet
        self._save_listings(all_listings)
        
        print("\n" + "=" * 60)
        print(f"âœ… TAMAMLANDI: {len(all_listings)} ilan Ã§ekildi")
        print(f"ğŸ“ Veri: {DATA_DIR / 'listings_full.json'}")
        print("=" * 60)
        
        return all_listings
    
    async def scrape_listing(self, url: str) -> dict:
        """Tek ilan detayÄ±nÄ± Ã§ek"""
        try:
            if not await self.get_page_safe(url):
                return None
            
            # TÃ¼m verileri JS ile Ã§ek
            data_js = """
            (() => {
                const data = {};
                
                // URL ve ID
                data.url = window.location.href;
                data.id = window.location.href.match(/-(\\d+)\\/detay/)?.[1] || '';
                
                // BaÅŸlÄ±k
                data.title = document.querySelector('h1')?.innerText?.trim() || '';
                
                // Fiyat
                const priceEl = document.querySelector('.classifiedInfo h3, .price-container, [class*="price"] h3');
                data.price = priceEl?.innerText?.trim() || '';
                
                // Konum
                data.location = document.querySelector('.classifiedInfo h2, .location')?.innerText?.trim() || '';
                
                // AÃ§Ä±klama
                data.description = document.querySelector('#classifiedDescription, .classifiedDescription')?.innerText?.trim() || '';
                
                // Ã–zellikler tablosu
                data.specs = {};
                document.querySelectorAll('.classifiedInfoList li, .classified-info-list li').forEach(li => {
                    const strong = li.querySelector('strong');
                    const span = li.querySelector('span');
                    if (strong && span) {
                        const key = strong.innerText.replace(':', '').trim();
                        const val = span.innerText.trim();
                        if (key && val) data.specs[key] = val;
                    }
                });
                
                // FotoÄŸraflar - birden fazla yÃ¶ntem
                data.images = [];
                
                // YÃ¶ntem 1: Galeri thumbnail'larÄ±
                document.querySelectorAll('.classifiedDetailPhotos img, .thumbs img').forEach(img => {
                    let src = img.src || img.dataset.src || '';
                    if (src && src.includes('shbdn')) {
                        // KÃ¼Ã§Ã¼k resmi bÃ¼yÃ¼k resme Ã§evir
                        src = src.replace(/_t\\.(jpg|png|jpeg)/i, '.$1')
                                 .replace(/\\/s\\//g, '/x/');
                        data.images.push(src);
                    }
                });
                
                // YÃ¶ntem 2: Data attribute'lardan
                document.querySelectorAll('[data-large-img], [data-original]').forEach(el => {
                    const src = el.dataset.largeImg || el.dataset.original;
                    if (src && !data.images.includes(src)) {
                        data.images.push(src);
                    }
                });
                
                // YÃ¶ntem 3: TÃ¼m bÃ¼yÃ¼k resimler
                document.querySelectorAll('img').forEach(img => {
                    const src = img.src;
                    if (src && src.includes('shbdn') && src.includes('/x/') && !data.images.includes(src)) {
                        data.images.push(src);
                    }
                });
                
                // SatÄ±cÄ± bilgisi
                data.seller = document.querySelector('.username-info-area, .store-name')?.innerText?.trim() || '';
                
                // Tarih
                data.date = document.querySelector('.classifiedInfo .date, [class*="date"]')?.innerText?.trim() || '';
                
                // Ä°lan numarasÄ± (sayfa iÃ§inde)
                const pageText = document.body.innerText;
                const ilanNo = pageText.match(/Ä°lan No[:\\s]*(\\d+)/i)?.[1];
                if (ilanNo) data.id = ilanNo;
                
                // Breadcrumb (kategori)
                data.category = document.querySelector('.breadcrumb, .classified-category')?.innerText?.trim() || '';
                
                return data;
            })()
            """
            
            result = await self.page.evaluate(data_js)
            
            # Nodriver value extraction
            listing = {}
            if isinstance(result, list):
                for item in result:
                    if isinstance(item, list) and len(item) == 2:
                        key, val = item
                        if isinstance(val, dict):
                            if val.get('type') == 'object':
                                # Nested object (specs)
                                listing[key] = self._extract_nested(val)
                            elif 'value' in val:
                                listing[key] = val['value']
                            else:
                                listing[key] = val
                        else:
                            listing[key] = val
            elif isinstance(result, dict):
                listing = result
            
            return listing if listing.get('title') or listing.get('id') else None
            
        except Exception as e:
            print(f"   Hata: {e}")
            return None
    
    def _extract_nested(self, val):
        """Nested object'i Ã§Ä±kar"""
        if isinstance(val, dict):
            if 'value' in val:
                return val['value']
            result = {}
            for k, v in val.items():
                if k not in ['type', 'subtype']:
                    result[k] = self._extract_nested(v)
            return result
        elif isinstance(val, list):
            return [self._extract_nested(v) for v in val]
        return val
    
    def _save_listings(self, listings: list):
        """Listing'leri kaydet"""
        with open(DATA_DIR / "listings_full.json", 'w', encoding='utf-8') as f:
            json.dump(listings, f, indent=2, ensure_ascii=False)
    
    async def close(self):
        """Browser'Ä± kapat"""
        if self.browser:
            await self.browser.stop()


async def main():
    scraper = SafeScraper()
    
    try:
        await scraper.start()
        
        # MaÄŸazayÄ± scrape et
        await scraper.scrape_store("https://kellerwillamskarma.sahibinden.com")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ KullanÄ±cÄ± tarafÄ±ndan durduruldu")
    except Exception as e:
        print(f"\nâŒ Hata: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await scraper.close()


if __name__ == "__main__":
    uc.loop().run_until_complete(main())
